{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKhFzZq5O0GT"
      },
      "outputs": [],
      "source": [
        "!pip install simpletransformers transformers==4.40.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the required packages\n",
        "\n",
        "# Dataframes\n",
        "import pandas as pd, numpy as np\n",
        "\n",
        "# Regular expressions\n",
        "import re\n",
        "\n",
        "# Unidecoder\n",
        "import unicodedata\n",
        "\n",
        "# Timestamp / time measurment\n",
        "import time\n",
        "\n",
        "# for train/test data preparation\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Label encode\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Class weights\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Model performance scores\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "\n",
        "# PyTorch: enable GPU access\n",
        "import torch\n",
        "\n",
        "# Simpletransformers classifier\n",
        "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n"
      ],
      "metadata": {
        "id": "mmV1FmmHO7RL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "AOjFoKewPFqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data\n",
        "dat = pd.read_csv('training_data.csv')\n",
        "\n",
        "dat['final_climate']=dat['final_climate'].astype(int)\n",
        "dat['final_climate'].sum()"
      ],
      "metadata": {
        "id": "0cMAAiOhO-mL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Â set qs_id as index b\n",
        "dat.set_index(\"qs_id\", drop = False, inplace = True, verify_integrity = True)"
      ],
      "metadata": {
        "id": "rtqTTTdIO-yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make numeric labels\n",
        "dat[\"label\"] = dat[\"final_broad\"].astype(\"category\").cat.codes\n",
        "dat[\"label\"].value_counts()"
      ],
      "metadata": {
        "id": "Ry1j2tGxO-6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make stratifications of data by langauge and climate relevance, from https://stackoverflow.com/a/62918682\n",
        "dat[\"strata_\"] = dat.set_index(['language','label']).index.factorize()[0]"
      ],
      "metadata": {
        "id": "KgL5_tUrO_Az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up GPU"
      ],
      "metadata": {
        "id": "1FIdrNc2QE-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If you want to select a specific GPU, set it here:\n",
        "# gpu = 0\n",
        "# torch.cuda.set_device(gpu)\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use GPU {}:'.format(torch.cuda.current_device()), torch.cuda.get_device_name(torch.cuda.current_device()))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "IhYb_UEgO_G6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up for cross validation"
      ],
      "metadata": {
        "id": "qo_7eFTBQOBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# separate 10% validation set\n",
        "val_df = dat.sample(frac=.2)\n",
        "train_data = dat.iloc[~val_df.index]"
      ],
      "metadata": {
        "id": "eet7xQ3cO_MS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up model arguments based on optimisation results\n",
        "model_type = \"xlmroberta\"\n",
        "model_name = \"xlm-roberta-base\"\n",
        "\n",
        "model_args = ClassificationArgs()\n",
        "model_args.reprocess_input_data = True\n",
        "model_args.overwrite_output_dir = True\n",
        "model_args.evaluate_during_training = False\n",
        "model_args.manual_seed = 4\n",
        "model_args.use_multiprocessing = True\n",
        "\n",
        "model_args.train_batch_size = 8\n",
        "model_args.eval_batch_size = 8\n",
        "model_args.num_train_epochs = 2\n",
        "model_args.learning_rate= 1e-5\n",
        "model_args.max_seq_length = 256\n",
        "model_args.sliding_window = True\n",
        "model_args.stride = 0.6\n",
        "model_args.weight_decay = 0\n",
        "\n",
        "model_args.labels_list = [0,1]\n",
        "model_args.no_save = True\n",
        "model_args.save_model_every_epoch=False\n",
        "model_args.save_optimizer_and_scheduler=False"
      ],
      "metadata": {
        "id": "mQhK1EPeO_Ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "seed=4\n",
        "n=5\n",
        "kf = StratifiedKFold(n_splits=n, random_state=seed, shuffle=True)\n",
        "\n",
        "# Load the label encoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "results_dict = dict()\n",
        "preds_dict = dict()\n",
        "\n",
        "n=0\n",
        "for train_index, test_index in kf.split(dat.index,dat.strata_):\n",
        "\n",
        "    # create train, val, test dfs\n",
        "    train_df = pd.DataFrame(zip(dat.iloc[train_index]['original_text'].values,dat.iloc[train_index]['clim_pol_rel'].values),columns=['text','labels'])\n",
        "    test_df = pd.DataFrame(zip(dat.iloc[test_index]['original_text'].values,dat.iloc[test_index]['clim_pol_rel'].values),columns=['text','labels'])\n",
        "\n",
        "    # Encode the labels\n",
        "    train_df['labels'] = label_encoder.fit_transform(train_df.labels)\n",
        "    test_df['labels'] = label_encoder.fit_transform(test_df.labels)\n",
        "\n",
        "    weights = compute_class_weight(class_weight = 'balanced', classes=[0,1], y=train_df.labels)\n",
        "    weights = [*weights]\n",
        "\n",
        "    print(train_df.shape, test_df.shape)\n",
        "\n",
        "    model = ClassificationModel(model_type, model_name, weight=weights, num_labels=2, args=model_args)\n",
        "    model.train_model(train_df)\n",
        "    result, model_outputs, wrong_predictions = model.eval_model(test_df,\n",
        "                                                                f1_score = f1_score,\n",
        "                                                                acc=accuracy_score,\n",
        "                                                                recall=recall,\n",
        "                                                                precision=precision)\n",
        "\n",
        "    print(f'Fold: {n}')\n",
        "    print(result)\n",
        "    results_dict[n]=result\n",
        "\n",
        "    preds,output = model.predict(test_df['text'].tolist())\n",
        "    true_labels = test_df['labels']\n",
        "    print(classification_report(true_labels, preds))\n",
        "\n",
        "    test_df['preds']=preds\n",
        "    test_df['original_text']=test_df['text']\n",
        "    preds_merged = dat.merge(test_df,on='original_text',how='inner')\n",
        "    preds_dict[n]=preds_merged\n",
        "\n",
        "    n+=1"
      ],
      "metadata": {
        "id": "-cAAcj_BQp27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile overall results\n",
        "results = pd.DataFrame()\n",
        "for k,v in results_dict.items():\n",
        "  out = pd.DataFrame(v.values(),index=v.keys()).T\n",
        "  rd = pd.concat([rd,out])\n",
        "results.reset_index(inplace=True,drop=True)\n",
        "results"
      ],
      "metadata": {
        "id": "ise228RhQznT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save\n",
        "results.to_csv('cv_overall_results.csv')"
      ],
      "metadata": {
        "id": "vyc2gFdBQ42s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile per langauge results\n",
        "overall_lang_perf=pd.DataFrame()\n",
        "for k in preds_dict.keys():\n",
        "  lang_fold_perf = dict()\n",
        "  for i in preds_dict[k]['language'].unique():\n",
        "    print(i)\n",
        "    s = preds_dict[k][preds_dict[k]['language']==i]\n",
        "    lang_fold_perf[i]=classification_report(s['labels'], s['preds'],output_dict=True)['1']['f1-score']\n",
        "  out = pd.DataFrame(lang_fold_perf.values(),index=lang_fold_perf.keys()).T\n",
        "  overall_lang_perf=pd.concat([overall_lang_perf,out])\n"
      ],
      "metadata": {
        "id": "0dRBT5PfQ_id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save\n",
        "overall_lang_perf.to_csv('language_performance.csv')"
      ],
      "metadata": {
        "id": "QEzl43woRLy6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}